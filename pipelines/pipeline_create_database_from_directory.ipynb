{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASOS PARA AÑADIR UN FICHERO A LA BASE DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No añadido: ⬜. Integrados en BD: ☑️. Integrados en BD vectorial: ✅.\n",
    "* ✅ zbe_oviedo\n",
    "* ✅ zbe_elche\n",
    "* ✅ gemelo_las_rozas\n",
    "* ✅ zbe_merida\n",
    "* ✅ ruido (26 elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = r\"C:/Users/jgpg000.edu/Desktop/Agente inteligente recuperación sensórica IoT/\"\n",
    "\n",
    "# ruta clases personalizadas\n",
    "import sys\n",
    "path_classes = f\"{path_root}classes\"\n",
    "sys.path.append(path_classes)\n",
    "\n",
    "## LIBRERIAS\n",
    "import pandas as pd\n",
    "from class_data import *\n",
    "from class_dataset import *\n",
    "from fun_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos los documentos (la primera vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:14<00:57, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] El archivo novatel-GNSS-800-Series-GM-14915147-v1.3 ya está guardado en la ruta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:49<03:05, 61.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] El archivo ale-omniswitch-2360-row-version-datasheet-es ya está guardado en la ruta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:08<01:24, 42.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] El archivo neurallabs-NL-GHOST-AI-ES-2024 ya está guardado en la ruta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:36<00:36, 36.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] El archivo avigilon-rm7-wks-datasheet-es ya está guardado en la ruta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:56<00:00, 35.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] El archivo fortinet-fortigate-400f-series ya está guardado en la ruta.\n",
      "Se han creado 5 documentos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_excel = f\"{path_root}datasets/database_items/item_reduced.xlsx\"\n",
    "path_saved_json = f\"{path_root}datasets/database_items/database_json/\"\n",
    "items_folder = f\"{path_root}datasets/database_items/projects/\"\n",
    "\n",
    "documents = create_documents(path_excel, path_saved_json, items_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos los documentos a partir de los archivos json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 248.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han cargado 5 documentos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_excel = f\"{path_root}datasets/database_items/item_reduced.xlsx\"\n",
    "path_saved_json = f\"{path_root}datasets/database_items/database_json/\"\n",
    "\n",
    "documents = load_documents(path_excel, path_saved_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez generado los json ya se encuentran almacenados en nuestro \"repositorio\" de objetos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertimos de la clase \"Documento\" a la propia de LangChain \"Document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han generado 31 documentos de Langchain.\n",
      "De ellos, 5 son el texto y 26 son resúmenes de tablas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "documents_langchain = load_documents_langchain(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los documentos en trozos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 319 trozos de texto\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# Dividimos cada texto en chunks\n",
    "chunks_text = text_splitter.split_documents(documents_langchain)\n",
    "print(f\"Hay {len(chunks_text)} trozos de texto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de la longitud media de los chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud media del chunk:\n",
      " 282.0689655172414\n"
     ]
    }
   ],
   "source": [
    "tex = 0\n",
    "for chunk in chunks_text:\n",
    "    tex += len(chunk.page_content)\n",
    "print(\"Longitud media del chunk:\\n\", tex/len(chunks_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Añadimos los trozos de texto a la base vectorial\n",
    "\n",
    "Se almacena su representación vectorial en la carpeta indicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacio creado correctamente. Contiene 319 vectores.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "path_saved_vector = f\"{path_root}datasets/database_items/database_vectorial/\"\n",
    "name_database = \"large_esp\"\n",
    "\n",
    "vectorstore = create_database(f\"{path_saved_vector}{name_database}\",\n",
    "                               chunks_text, nombre_embedding = \"text-embedding-3-large\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
