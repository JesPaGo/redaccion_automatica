{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = r\"C:/Users/jgpg000.edu/Desktop/Agente inteligente recuperación sensórica IoT/\"\n",
    "\n",
    "# ruta clases personalizadas\n",
    "import sys\n",
    "path_classes = f\"{path_root}classes\"\n",
    "sys.path.append(path_classes)\n",
    "\n",
    "## LIBRERIAS\n",
    "import pandas as pd\n",
    "from class_data import *\n",
    "from class_dataset import *\n",
    "from fun_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agente inteligente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 319.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han cargado 86 documentos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 9702.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han generado 954 documentos de Langchain.\n",
      "    De ellos, 86 son el texto y 868 son resúmenes de tablas.\n",
      "Hay 7218 chunks de texto.\n"
     ]
    }
   ],
   "source": [
    "path_excel = f\"{path_root}datasets/database_items/item_list.xlsx\"\n",
    "path_saved_json = f\"{path_root}datasets/database_items/database_json/\"\n",
    "\n",
    "documentos = load_documents(path_excel, path_saved_json)\n",
    "documentos_langchain = load_documents_langchain(documentos)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Aplicamos el splitter de Langchain\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# Dividimos cada texto en chunks\n",
    "chunks_texto = text_splitter.split_documents(documentos_langchain)\n",
    "print(f\"Hay {len(chunks_texto)} chunks de texto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_vector = f\"{path_root}datasets/database_items/database_vectorial/\"\n",
    "name_database = \"large_esp\"\n",
    "modelo_llm = \"gpt-4o\"\n",
    "\n",
    "template_sistema = \"\"\" Eres un asistente de una empresa encargada de smart cities.\n",
    "Como preguntas, te van a adjuntar listas de requisitos de equipo para proyecto.\n",
    "Tu labor es responder con el nombre de los equipos que encuentres que cumplan los requisitos, así como suministrar la información de estos dispositivos en relación a los requisitos.\n",
    "Usa la información añadida en el contexto para responder a la pregunta pero no hagas referencias al mismo.\n",
    "Se añade como metadato tanto el proveedor como el nombre a los que pertenece el contexto devuelto.\n",
    "Responde únicamente con la especificación que se pide. Si no aparece di que no lo sabes.\n",
    "Pregunta: {question}\n",
    "Metadato: {metadata}\n",
    "Contexto: {contexts}\n",
    "La respuesta debe tener el siguiente formato:\n",
    "- Nombre del equipo y proveedor.\n",
    "- Especificaciones que se han preguntado y aparecen en el contexto.\n",
    "Respuesta:\n",
    "\"\"\"\n",
    "# Creamos la vectorstore\n",
    "vectorstore = create_database(f\"{path_saved_vector}{name_database}\",\n",
    "                               chunks_texto, nombre_embedding = \"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo como una clase para que mantenga el formato de llamadas con .invoke\n",
    "\n",
    "```from class_rag_mode import mode_item_global```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta_ejemplo = '''Se requiere de un sonómetro clase II LoRa que disponga de  las siguientes especificaciones como mínimo:\n",
    "- Rango: 40 dB a 115 dB. \n",
    "- Frecuencia de ponderación A.\n",
    "- Capacidad para proveer diferentes ponderaciones para el correcto estudio del ruido: LAeq, \n",
    "LA1, LA10, LA50, LA90, LA99, LAmax, LAmin, LA Slow o LA Fast entre otros.\n",
    "- Detección de picos.\n",
    "- Consumo: 40 mA.\n",
    "- Protector contra viento.\n",
    "- Voltaje de operación: 3.6 a 6V.\n",
    "- Normativa IEC 61672-1.\n",
    "- Certificación: ROHS / CE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B&K 2245', 15), ('Smart Spot Sound level Meter clase II', 8), ('Clase 1 modelo TA120', 7)] :  [('HBK', 15), ('Hopu', 8), ('CESVA', 7)]\n"
     ]
    }
   ],
   "source": [
    "from class_rag_mode import rag_mode_global\n",
    "productos, proveedores = rag_mode_global.mode_item_global(vectorstore,\n",
    "                        pregunta = pregunta_ejemplo,\n",
    "                        k=3,\n",
    "                        num_productos_maximo=3,\n",
    "                        tipo_equipo=\"sonometro\",\n",
    "                        path_item_list = path_excel)\n",
    "print(productos,\": \", proveedores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG creado correctamente.\n",
      "        Llámalo con <rag_name>.invoke(<query>, tipo_equipo, k, num_productos_maximo)\n",
      "Productos elegidos: ['B&K 2245', 'Smart Spot Sound level Meter clase II', 'Clase 1 modelo TA120']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Nombre del equipo y proveedor: Smart Spot Sound level Meter clase II, Hopu.\\n- Especificaciones que se han preguntado y aparecen en el contexto:\\n  - Rango: 40 dB a 115 dB.\\n  - Frecuencia de ponderación A.\\n  - Capacidad para proveer diferentes ponderaciones para el correcto estudio del ruido: LAeq, LA1, LA10, LA50, LA90, LA99, LAmax, LAmin, LA Slow, LA Fast.\\n  - Detección de picos.\\n  - Normativa IEC 61672-1.\\n  - Certificación: ROHS / CE.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from class_rag_mode import rag_mode_global\n",
    "RAG_mode = rag_mode_global(vectorstore, verbose=True)\n",
    "response = RAG_mode.invoke(pregunta_ejemplo,\n",
    "                        tipo_equipo=\"sonometro\",\n",
    "                        k=3, # Productos extraidos por sentencia\n",
    "                        num_productos_maximo=3)\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interfaz gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict(message, history):\n",
    "    response = RAG_mode.invoke(message)\n",
    "    return response['answer']\n",
    "\n",
    "gr.ChatInterface(predict).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
