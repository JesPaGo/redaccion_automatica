{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jgpg000.edu\\AppData\\Local\\anaconda3\\envs\\management\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "path_root = r\"C:/Users/jgpg000.edu/Desktop/Agente inteligente recuperación sensórica IoT/\"\n",
    "\n",
    "# ruta clases personalizadas\n",
    "import sys\n",
    "path_classes = f\"{path_root}classes\"\n",
    "sys.path.append(path_classes)\n",
    "\n",
    "## LIBRERIAS\n",
    "import pandas as pd\n",
    "from class_data import *\n",
    "from fun_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agente inteligente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 222.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han cargado 86 documentos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 7641.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han generado 954 documentos de Langchain.\n",
      "    De ellos, 86 son el texto y 868 son resúmenes de tablas.\n",
      "Hay 7218 chunks de texto.\n"
     ]
    }
   ],
   "source": [
    "path_excel = f\"{path_root}datasets/database_items/item_list.xlsx\"\n",
    "path_saved_json = f\"{path_root}datasets/database_items/database_json/\"\n",
    "\n",
    "documentos = load_documents(path_excel, path_saved_json)\n",
    "documentos_langchain = load_documents_langchain(documentos)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Aplicamos el splitter de Langchain\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# Dividimos cada texto en chunks\n",
    "chunks_texto = text_splitter.split_documents(documentos_langchain)\n",
    "print(f\"Hay {len(chunks_texto)} chunks de texto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_vector = f\"{path_root}datasets/database_items/database_vectorial/\"\n",
    "name_database = \"large_esp\"\n",
    "model_llm = \"gpt-4o\"\n",
    "\n",
    "template_sistema = \"\"\" Eres un asistente de una empresa encargada de smart cities.\n",
    "Como preguntas, te van a adjuntar listas de requisitos de equipo para proyecto.\n",
    "Tu labor es responder con el nombre de los equipos que encuentres que cumplan los requisitos, así como suministrar la información de estos dispositivos en relación a los requisitos.\n",
    "Usa la información añadida en el contexto para responder a la pregunta pero no hagas referencias al mismo.\n",
    "Se añade como metadato tanto el proveedor como el nombre a los que pertenece el contexto devuelto.\n",
    "Responde únicamente con la especificación que se pide. Si no aparece di que no lo sabes.\n",
    "Pregunta: {question}\n",
    "Metadato: {metadata}\n",
    "Contexto: {contexts}\n",
    "La respuesta debe tener el siguiente formato:\n",
    "- Nombre del equipo y proveedor.\n",
    "- Especificaciones que se han preguntado y aparecen en el contexto.\n",
    "Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "vectorstore = create_database(f\"{path_saved_vector}{name_database}\",\n",
    "                               chunks_texto, nombre_embedding = \"text-embedding-3-large\")\n",
    "retriever = create_retriever(vectorstore)\n",
    "rag = create_RAG(retriever=retriever,\n",
    "                plantilla_RAG=template_sistema,\n",
    "                model=model_llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Añadimos filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Nombre del equipo y proveedor: MikroTik hEX PoE, MikroTik.\\n- Especificaciones: 5 puertos Ethernet (de los cuales 4 pueden alimentar otros dispositivos), 1 puerto USB 2.0.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_filtrado = rag_filter(vectorstore, \n",
    "                        equipo=\"router\",\n",
    "                        template_system=template_sistema,\n",
    "                        model_llm=model_llm)\n",
    "\n",
    "response = rag_filtrado.invoke(\"Necesito un router con 4 puertos ethernet y 2 puertos USB.\")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interfaz gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict(message, history):\n",
    "    response = rag_filtrado.invoke(message)\n",
    "    return response['answer']\n",
    "\n",
    "gr.ChatInterface(predict).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
