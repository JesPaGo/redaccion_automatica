{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = r\"C:/Users/jgpg000.edu/Desktop/Agente inteligente recuperación sensórica IoT/\"\n",
    "\n",
    "# ruta clases personalizadas\n",
    "import sys\n",
    "path_classes = f\"{path_root}classes\"\n",
    "sys.path.append(path_classes)\n",
    "\n",
    "## LIBRERIAS\n",
    "import pandas as pd\n",
    "from class_data import *\n",
    "from fun_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agente inteligente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 196.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han cargado 86 documentos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 3285.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han generado 954 documentos de Langchain.\n",
      "De ellos, 86 son el texto y 868 son resúmenes de tablas.\n",
      "Hay 7218 chunks de texto.\n"
     ]
    }
   ],
   "source": [
    "path_excel = f\"{path_root}datasets/database_items/item_list.xlsx\"\n",
    "path_saved_json = f\"{path_root}datasets/database_items/database_json/\"\n",
    "\n",
    "documentos = load_documents(path_excel, path_saved_json)\n",
    "documentos_langchain = load_documents_langchain(documentos)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Aplicamos el splitter de Langchain\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# Dividimos cada texto en chunks\n",
    "chunks_texto = text_splitter.split_documents(documentos_langchain)\n",
    "print(f\"Hay {len(chunks_texto)} chunks de texto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacio creado correctamente. Contiene 7218 vectores.\n",
      "Retriever creado correctamente.\n",
      "RAG creado correctamente.\n",
      "    Llámalo con <rag_name>.invoke(<query>)\n"
     ]
    }
   ],
   "source": [
    "path_saved_vector = f\"{path_root}datasets/database_items/database_vectorial/\"\n",
    "name_database = \"large_esp\"\n",
    "modelo_llm = \"gpt-4o\"\n",
    "\n",
    "template_sistema = \"\"\" Eres un asistente de una empresa encargada de smart cities.\n",
    "Como preguntas, te van a adjuntar listas de requisitos de equipo para proyecto.\n",
    "Tu labor es responder con el nombre de los equipos que encuentres que cumplan los requisitos, así como suministrar la información de estos dispositivos en relación a los requisitos.\n",
    "Usa la información añadida en el contexto para responder a la pregunta pero no hagas referencias al mismo.\n",
    "Se añade como metadato tanto el proveedor como el nombre a los que pertenece el contexto devuelto.\n",
    "Responde únicamente con la especificación que se pide. Si no aparece di que no lo sabes.\n",
    "Pregunta: {question}\n",
    "Metadato: {metadata}\n",
    "Contexto: {contexts}\n",
    "La respuesta debe tener el siguiente formato:\n",
    "- Nombre del equipo y proveedor.\n",
    "- Especificaciones que se han preguntado y aparecen en el contexto.\n",
    "Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "vectorstore = create_database(f\"{path_saved_vector}{name_database}\",\n",
    "                               chunks_texto, nombre_embedding = \"text-embedding-3-large\")\n",
    "retriever = create_retriever(vectorstore)\n",
    "rag = create_RAG(retriever=retriever,\n",
    "                plantilla_RAG=template_sistema,\n",
    "                model=modelo_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m pregunta_ejemplo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mSe requiere de un sonómetro clase II LoRa que disponga de  las siguientes especificaciones como mínimo:\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m- Rango: 40 dB a 115 dB. \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m- Frecuencia de ponderación A \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m- Certificación: ROHS / CE \u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mrag\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(pregunta_ejemplo)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rag' is not defined"
     ]
    }
   ],
   "source": [
    "pregunta_ejemplo = '''Se requiere de un sonómetro clase II LoRa que disponga de  las siguientes especificaciones como mínimo:\n",
    "- Rango: 40 dB a 115 dB. \n",
    "- Frecuencia de ponderación A.\n",
    "- Capacidad para proveer diferentes ponderaciones para el correcto estudio del ruido: LAeq, \n",
    "LA1, LA10, LA50, LA90, LA99, LAmax, LAmin, LA Slow o LA Fast entre otros.\n",
    "- Detección de picos.\n",
    "- Consumo: 40 mA.\n",
    "- Protector contra viento.\n",
    "- Voltaje de operación: 3.6 a 6V.\n",
    "- Normativa IEC 61672-1.\n",
    "- Certificación: ROHS / CE.\n",
    "'''\n",
    "\n",
    "rag.invoke(pregunta_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interfaz gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict(message, history):\n",
    "    response = rag.invoke(message)\n",
    "    return response['answer']\n",
    "\n",
    "gr.ChatInterface(predict).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuestas a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = f\"{path_root}datasets/test/QA_Dataset.xlsx\"\n",
    "qa = QADataset(path_dataset, sheet_name=\"Hoja1\")\n",
    "qa.show()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = qa.generar_respuesta_individual(rag, 0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.generar_respuestas(rag)\n",
    "qa.show()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GUARDAMOS EL DATASET CON LAS RESPUESTAS GENERADAS POR EL MODELO\n",
    "## formato nombre: QA-modelo-Q#: QA-(modeloRAG)-(num. preg. dataset)\n",
    "path_save_dataset = f\"{path_root}testing/responses_test/csv/\"\n",
    "model_name = \"QA-baseline_esp_large-Q16\"\n",
    "\n",
    "qa.guardar(path_save_dataset, model_name) # guarda en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_dataset = f\"{path_root}testing/responses_test/csv/\"\n",
    "model_name = \"QA-baseline_esp_large-Q16\"\n",
    "## Comprobar que se ha guardado correctamente (cargando el modelo)\n",
    "qa = QADataset(f\"{path_save_dataset}{model_name}.csv\")\n",
    "qa.show_metrics()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluamos la calidad de las respuestas generadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LISTA METRICAS #####\n",
    "# ['answer_relevancy', 'context_relevancy', 'context_recall', 'answer_similarity',\n",
    "# 'answer_correctness', 'precision_bertscore', 'recall_bertscore', 'f1_bertscore',\n",
    "# 'mismo_producto', 'especificaciones_correctas', 'especificaciones_correctas_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import context_relevancy, answer_similarity, answer_correctness\n",
    "metricas = [context_relevancy, answer_similarity, answer_correctness]\n",
    "\n",
    "# generamos todas las métricas con el siguiente bucle\n",
    "result_ragas = qa.ragas(metricas= metricas)\n",
    "qa.bertscore()\n",
    "qa.es_mismo_producto(modelo_llm=\"gpt-4o\")\n",
    "qa.son_especificaciones_correctas(modelo_llm=\"gpt-4o\")\n",
    "\n",
    "# Guardamos el dataset con métricas\n",
    "path_save_dataset = f\"{path_root}testing/response_test/csv/\"\n",
    "model_name = \"QA-baseline_esp_large-Q16\"\n",
    "qa.guardar(path_save_dataset, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluimos la métrica del número de especificaciones correctas normalizadas\n",
    "path_dataset = f\"{path_root}datasets/test/QA_Dataset.xlsx\"\n",
    "dataset = pd.read_excel(path_dataset, sheet_name=\"QA2\", dtype=str, header=0)\n",
    "num_especificaciones = dataset['nº ENCONTRADAS EN DATASHEET'].dropna().astype(int).reset_index(drop=True)\n",
    "\n",
    "qa.son_especificaciones_correctas_norm(num_especificaciones)\n",
    "qa.guardar(path_save_dataset, model_name)\n",
    "qa.especificaciones_correctas_norm[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La QA correcta 14 tiene tantas especificaciones_correctas sin acertar el producto porque la mayoría de la ground_truth es \"no lo sé\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = QADataset.columnas_metricas.copy()\n",
    "metricas.remove(\"especificaciones_correctas\")\n",
    "metricas.remove(\"answer_relevancy\")\n",
    "metricas.remove(\"context_recall\")\n",
    "\n",
    "path_figures = f\"{path_root}testing/figures_test/\"\n",
    "model_name = \"QA-baseline_esp_large-Q16\"\n",
    "qa.grafico(model_name, path_figures, metricas = metricas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
